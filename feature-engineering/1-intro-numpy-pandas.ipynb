{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction to NumPy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "This chapter outlines techniques for effectively loading, storing, and manipulating in-memory data in Python.\n",
    "The topic is very broad: datasets can come from a wide range of sources and a wide range of formats, including be collections of documents, collections of images, collections of sound clips, collections of numerical measurements, or nearly anything else.\n",
    "Despite this apparent heterogeneity, it will help us to think of all data fundamentally as arrays of numbers.\n",
    "\n",
    "For example, images–particularly digital images–can be thought of as simply two-dimensional arrays of numbers representing pixel brightness across the area.\n",
    "Sound clips can be thought of as one-dimensional arrays of intensity versus time.\n",
    "Text can be converted in various ways into numerical representations, perhaps binary digits representing the frequency of certain words or pairs of words.\n",
    "No matter what the data are, the first step in making it analyzable will be to transform them into arrays of numbers.\n",
    "\n",
    "For this reason, efficient storage and manipulation of numerical arrays is absolutely fundamental to the process of doing data science.\n",
    "We'll now take a look at the specialized tools that Python has for handling such numerical arrays: the `NumPy` package, and the `Pandas` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "NumPy (short for *Numerical Python*) provides an efficient interface to store and operate on dense data buffers.\n",
    "In some ways, NumPy arrays are like Python's built-in ``list`` type, but NumPy arrays provide much more efficient storage and data operations as the arrays grow larger in size.\n",
    "NumPy arrays form the core of nearly the entire ecosystem of data science tools in Python, so time spent learning to use NumPy effectively will be valuable no matter what aspect of data science interests you.\n",
    "\n",
    "If you followed the advice outlined in the Preface and installed the Anaconda stack, you already have NumPy installed and ready to go.\n",
    "If you're more the do-it-yourself type, you can go to http://www.numpy.org/ and follow the installation instructions found there.\n",
    "Once you do, you can import NumPy and double-check the version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the pieces of the package discussed here, I'd recommend NumPy version 1.8 or later.\n",
    "By convention, you'll find that most people in the SciPy/PyData world will import NumPy using ``np`` as an alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Throughout this chapter, and indeed the rest of the book, you'll find that this is the way we will import and use NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reminder about Built In Documentation\n",
    "\n",
    "As you read through this chapter, don't forget that IPython gives you the ability to quickly explore the contents of a package (by using the tab-completion feature), as well as the documentation of various functions (using the ``?`` character).\n",
    "\n",
    "For example, to display all the contents of the numpy namespace, you can type this:\n",
    "\n",
    "```ipython\n",
    "In [3]: np.<TAB>\n",
    "```\n",
    "\n",
    "And to display NumPy's built-in documentation, you can use this:\n",
    "\n",
    "```ipython\n",
    "In [4]: np?\n",
    "```\n",
    "\n",
    "More detailed documentation, along with tutorials and other resources, can be found at http://www.numpy.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Here we'll build on this knowledge by looking in detail at the data structures provided by the Pandas library.\n",
    "\n",
    "\n",
    "Pandas is a **newer package built on top of NumPy**, and provides an efficient implementation of a ``DataFrame``.\n",
    "\n",
    "``DataFrame``s are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data.\n",
    "As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
    "\n",
    "As we saw, NumPy's ``ndarray`` data structure provides essential features for the type of clean, well-organized data typically seen in numerical computing tasks.\n",
    "While it serves this purpose very well, its limitations become clear when we need more flexibility (e.g., attaching labels to data, working with missing data, etc.) and when attempting operations that do not map well to element-wise broadcasting (e.g., groupings, pivots, etc.), each of which is an important piece of analyzing the less structured data available in many forms in the world around us.\n",
    "Pandas, and in particular its ``Series`` and ``DataFrame`` objects, builds on the NumPy array structure and provides efficient access to these sorts of \"data munging\" tasks that occupy much of a data scientist's time.\n",
    "\n",
    "In this chapter, we will focus on the mechanics of using ``Series``, ``DataFrame``, and related structures effectively.\n",
    "We will use examples drawn from real datasets where appropriate, but these examples are not necessarily the focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and Using Pandas\n",
    "\n",
    "Installation of Pandas on your system requires NumPy to be installed, and if building the library from source, requires the appropriate tools to compile the C and Cython sources on which Pandas is built.\n",
    "Details on this installation can be found in the [Pandas documentation](http://pandas.pydata.org/).\n",
    "\n",
    "Once Pandas is installed, you can import it and check the version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we generally import NumPy under the alias ``np``, we will import Pandas under the alias ``pd``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder about Built-In Documentation\n",
    "\n",
    "As you read through this chapter, don't forget that IPython gives you the ability to quickly explore the contents of a package (by using the tab-completion feature) as well as the documentation of various functions (using the ``?`` character).\n",
    "\n",
    "For example, to display all the contents of the pandas namespace, you can type\n",
    "\n",
    "```ipython\n",
    "In [3]: pd.<TAB>\n",
    "```\n",
    "\n",
    "And to display Pandas's built-in documentation, you can use this:\n",
    "\n",
    "```ipython\n",
    "In [4]: pd?\n",
    "```\n",
    "\n",
    "More detailed documentation, along with tutorials and other resources, can be found at http://pandas.pydata.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
